{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2b: Extract Near Miss Sequences (Fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "%matplotlib inline\n",
    "from google.cloud import bigquery\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "## GCP Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Google Cloud Authentication: \n",
    "assert os.system('gcloud auth application-default login --quiet') == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Insert your project ID here:\n",
    "PROJECT_ID = \"ford-5bba11084fd31e17ec109f0c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert os.system(f\"gcloud config set core/project {PROJECT_ID}\") == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[core]\n",
      "disable_usage_reporting = True\n",
      "project = ford-5bba11084fd31e17ec109f0c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your active configuration is: [default]\n"
     ]
    }
   ],
   "source": [
    "!gcloud config list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query:\n",
    "- Get the driving characteristics of the top [X] vins most active BlueCruise Vins that have a collision claim\n",
    "- Between [DATES OF INTEREST]\n",
    "- Initially looked at dates between 2023-01-01 and 2023-08-01 & the top 20 vins with the most data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT \n",
    "/* Identifiers */\n",
    "dpefa_bc_007_trip_d as trip_id,\n",
    "\n",
    "/*Time*/\n",
    "dpefa_bc_007_event_local_m as date_time,\n",
    "\n",
    "/* Driving Characteristics */\n",
    "dpefa_bc_007_hst_veh_long_vlcy_r as veh_long_vel_mps,\n",
    "dpefa_bc_007_hst_veh_ltrl_vlcy_r as veh_ltrl_vel_mps,\n",
    "dpefa_bc_007_hst_veh_yaw_rate_r as veh_yaw_rate_radps,\n",
    "dpefa_bc_007_acc_mps2 as veh_accel_mps2,\n",
    "dpefa_bc_007_jerk_mps3 as veh_jerk_mps3,\n",
    "\n",
    "\n",
    "FROM `prj-dfad-31-usrda-p-31.dlobo1_bluecruise.gdpefa_adas_bc_ada_lm_vw` /* Change this to your dataset */\n",
    "/* Make sure BC vins are in claims table */\n",
    "WHERE dpefa_bc_007_vin_17_x in (\n",
    "  SELECT DISTINCT bc.dpefa_bc_007_vin_17_x\n",
    "  FROM `prj-dfad-31-usrda-p-31.dlobo1_bluecruise.gdpefa_adas_bc_ada_lm_vw` as bc\n",
    "  INNER JOIN `ford-5bba11084fd31e17ec109f0c.GDIA_Credit.Management_Lease_All_Claims_Sep25`as claims\n",
    "  ON bc.dpefa_bc_007_vin_17_x = claims.VIN\n",
    "  WHERE bc.dpefa_bc_007_event_m BETWEEN '2023-1-1' AND '2023-8-1' /* SET DATES OF INTEREST */\n",
    "  AND claims.CauseCode = 'Collision'\n",
    ")\n",
    "AND dpefa_bc_007_event_m BETWEEN '2023-1-1' AND '2023-8-1'\n",
    "AND dpefa_bc_007_vin_17_x IN (SELECT\n",
    "  dpefa_bc_007_vin_17_x AS vin,\n",
    "  FROM `prj-dfad-31-usrda-p-31.dlobo1_bluecruise.gdpefa_adas_bc_ada_lm_vw`\n",
    "  WHERE dpefa_bc_007_vin_17_x IN (\n",
    "    SELECT DISTINCT bc.dpefa_bc_007_vin_17_x\n",
    "    FROM `prj-dfad-31-usrda-p-31.dlobo1_bluecruise.gdpefa_adas_bc_ada_lm_vw` AS bc\n",
    "    INNER JOIN `ford-5bba11084fd31e17ec109f0c.GDIA_Credit.Management_Lease_All_Claims_Sep25` AS claims\n",
    "    ON bc.dpefa_bc_007_vin_17_x = claims.VIN\n",
    "    WHERE bc.dpefa_bc_007_event_m BETWEEN '2023-1-1' AND '2023-8-1' /* SET DATES OF INTEREST */\n",
    "    AND claims.CauseCode = 'Collision'\n",
    "  )\n",
    "  AND dpefa_bc_007_event_m BETWEEN '2023-1-1' AND '2023-8-1' /* SET DATES OF INTEREST */\n",
    "  GROUP BY dpefa_bc_007_vin_17_x\n",
    "  ORDER BY COUNT(dpefa_bc_007_vin_17_x) DESC\n",
    "  LIMIT 20) /* SET NUMBER OF VINS OF INTEREST (Top X number of Vins with most BC data) */\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Excecute the query\n",
    "client = bigquery.Client()\n",
    "df = client.query(q)\n",
    "df_bc = df.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning:\n",
    "\n",
    "df_bc['date_time'] = pd.to_datetime(df_bc['date_time'], format='ISO8601') # Convert the date_time column to a datetime object with ISO8601 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving query df to a csv file\n",
    "df.to_csv('data/bc_claims_top20_jan_aug.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact Detection (Fingerprint Method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find impacts based on velocity dropping to zero for a duration of X seconds\n",
    "- X = 280 seconds (4.67 minutes) [This can be tuned]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_impacts(df, zero_speed_duration_threshold):\n",
    "    \"\"\"\n",
    "    Detects trips with potential impacts based on velocity dropping to zero.\n",
    "\n",
    "    Args:\n",
    "    df: DataFrame containing trip data.\n",
    "    zero_speed_duration_threshold: The number of consecutive seconds where the vehicle speed must be zero to consider it an impact.\n",
    "\n",
    "    Returns:\n",
    "    A list of trip numbers that have potential impacts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a function to identify if there is a stop in the trip\n",
    "    def is_impact(trip_data):\n",
    "        trip_data = trip_data.sort_values('date_time')\n",
    "        zero_velocities = trip_data['veh_long_vel_mps'] == 0\n",
    "        zero_velocities_duration = zero_velocities.groupby((zero_velocities != zero_velocities.shift()).cumsum()).cumsum()\n",
    "        return any(zero_velocities_duration >= zero_speed_duration_threshold)\n",
    "\n",
    "    # Group by trip number and apply the detection function\n",
    "    impacted_trips = df.groupby('trip_id').apply(is_impact)\n",
    "    \n",
    "    # Return trip numbers where an impact is detected\n",
    "    return impacted_trips[impacted_trips].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trips with potential impacts: [2672, 2791, 3612, 5039, 5159]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\donav\\AppData\\Local\\Temp\\ipykernel_27528\\2076283317.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  impacted_trips = df.groupby('trip_num').apply(is_impact)\n"
     ]
    }
   ],
   "source": [
    "# Find the trip numbers with potential impacts\n",
    "impacted_trips = detect_impacts(df_bc, zero_speed_duration_threshold=280)\n",
    "print(f\"Trips with potential impacts: {impacted_trips}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the impact indicator for the impacted trips\n",
    "- The impact indicator is set to 1 for the point in time with the maximum acceleration in the impact window\n",
    "- impact_indicator = 0 for all other points in time\n",
    "- impact_indicator is set to 0 for all trips that do not have an impact\n",
    "- impact window: 1 minute before the vehicle stops to the stop time [This can be tuned]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column called 'impact_indicator' that is initially set to 0 in the BlueCruise dataframe\n",
    "df_bc['impact_indicator'] = 0\n",
    "\n",
    "\n",
    "for trip_num in impacted_trips:\n",
    "    trip_data = df_bc[df_bc['trip_id'] == trip_num]\n",
    "    # Check if there are any zero velocity points in the data\n",
    "    if (trip_data['veh_long_vel_mps'] == 0).any():\n",
    "        # Find the earliest time when the vehicle velocity drops to zero\n",
    "        stop_time = trip_data[trip_data['veh_long_vel_mps'] == 0]['date_time'].min()\n",
    "        # Define the impact window: from one minute before the vehicle stops to the stop time\n",
    "        start_time = stop_time - pd.Timedelta(minutes=1)\n",
    "        \n",
    "        # Filter the data to the last minute before the vehicle stops\n",
    "        impact_window = trip_data[(trip_data['date_time'] >= start_time) & (trip_data['date_time'] <= stop_time)]\n",
    "        \n",
    "        # Find the time of the maximum absolute acceleration in this window\n",
    "        max_accel_idx = impact_window['veh_accel_mps2'].abs().idxmax()\n",
    "        \n",
    "        # Get the date_time for the max acceleration\n",
    "        if not impact_window.empty:\n",
    "            impact_time = impact_window.loc[max_accel_idx, 'date_time']\n",
    "            # Set the impact indicator to 1 for the row with the maximum acceleration\n",
    "            df_bc.loc[max_accel_idx, 'impact_indicator'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Near Miss Extraction\n",
    "- Extract X second near miss sequences before the impact time\n",
    "- X = 10 seconds [This can be tuned]\n",
    "- Uncertainty window: 3 seconds before and after the impact time [This can be tuned]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set window size variables:\n",
    "X = 10 # X-second sequence/ window size\n",
    "Y = 3 # Y-second uncertainty window size (The uncertainty of when the impact actually occurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc['seg_num_id'] = 0  # Initialize the segment number identifier\n",
    "segment_count = 0  # Initialize the segment counter for this trip\n",
    "\n",
    "# Create an empty DataFrame to store the window segments\n",
    "windows_df = pd.DataFrame()\n",
    "\n",
    "for trip_num in impacted_trips:\n",
    "    trip_data = df_bc[df_bc['trip_id'] == trip_num].copy()\n",
    "    impact_times = trip_data[trip_data['impact_indicator'] == 1]['date_time']\n",
    "    \n",
    "    # Process multiple windows around each impact\n",
    "    for impact_time in impact_times:\n",
    "        for offset in range(-Y, Y + 1):\n",
    "            window_start = impact_time - pd.Timedelta(seconds=X + 2) + pd.Timedelta(seconds=offset)\n",
    "            window_end = impact_time - pd.Timedelta(seconds=2) + pd.Timedelta(seconds=offset)\n",
    "            window = trip_data[(trip_data['date_time'] >= window_start) & (trip_data['date_time'] < window_end)].copy()\n",
    "            segment_count += 1\n",
    "            window['seg_num_id'] = segment_count  # Assign unique segment number within the trip\n",
    "            windows_df = pd.concat([windows_df, window])\n",
    "\n",
    "# Reset index for the windows DataFrame\n",
    "windows_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the near miss sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning:\n",
    "windows_df = windows_df.groupby('seg_num_id').filter(lambda x: len(x) >= 5) # Drop any segments that have less than 5 seconds of data based on seg_num_id\n",
    "windows_df.drop(columns=['impact_indicator'], inplace=True) # Drop impact_indicator column and save the windows_df to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned near miss sequences to a CSV file\n",
    "windows_df.to_csv('data/df_near_miss_windows_fingerprint.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m114"
  },
  "kernelspec": {
   "display_name": "env_bc_eda",
   "language": "python",
   "name": "env_bc_eda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
