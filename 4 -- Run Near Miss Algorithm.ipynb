{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Run Near Miss Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import near_miss_algorithms.near_miss_v3 as nma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Trips Dataset (BlueCruise [From step 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc = pd.read_csv('data/df_bc_trips_PLACEHOLDER.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Near Miss Sequences Dataset (From step 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_df = pd.read_csv('data/df_near_miss_windows_combined1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trip Duration Dataframe\n",
    "\n",
    "# Convert the date_time column to datetime format\n",
    "df_bc['date_time'] = pd.to_datetime(df_bc['date_time'], format='ISO8601')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Identification Functions\n",
    "- Utilitize Developed Near Miss Algorithm (keep python code in near_miss_algorithms folder)\n",
    "- Near Miss Algorithm Repo: https://github.com/DonavenLobo/FordxGatech_NearMissAlgo_Dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the combined distance profile\n",
    "def compute_combined_distance(query_df, trip_df, columns):\n",
    "    combined_distance_profile = nma.near_miss(trip_df[columns[0]].values, query_df[columns[0]].values)  # Initialize combined distance profile\n",
    "\n",
    "    # Loop through each column and compute the distance profile\n",
    "    for col in columns:\n",
    "        if col == columns[0]:\n",
    "            continue\n",
    "        distance_profile = nma.near_miss(trip_df[col].values, query_df[col].values)\n",
    "        combined_distance_profile += distance_profile  # Sum the distance profiles\n",
    "\n",
    "    return combined_distance_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute MASS for a single trip-query pair\n",
    "def compute_mass_for_trip(query_df, trip_df, query_num, trip_num, time_series_columns):\n",
    "    query_length = len(query_df)\n",
    "    trip_length = len(trip_df)\n",
    "\n",
    "    # Skip if the trip is shorter than the query\n",
    "    if trip_length < query_length:\n",
    "        return None\n",
    "\n",
    "    # Compute the combined distance profile\n",
    "    combined_distance_profile = compute_combined_distance(query_df, trip_df, time_series_columns)\n",
    "\n",
    "    # Remove nan values in the distance profile\n",
    "    # Remove trailing NaN values from the combined distance profile\n",
    "    first_nan_index = np.where(np.isnan(combined_distance_profile))[0][0] if np.any(np.isnan(combined_distance_profile)) else len(combined_distance_profile)\n",
    "    combined_distance_profile = combined_distance_profile[:first_nan_index]\n",
    "\n",
    "    # Compute the minimum  distance\n",
    "    min_distance = np.min(combined_distance_profile)\n",
    "\n",
    "    # Return the result as a dictionary\n",
    "    return {\n",
    "        'trip_num': trip_num,\n",
    "        'query_num': query_num,\n",
    "        'distance_profile': combined_distance_profile,\n",
    "        'min_distance': min_distance\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized function to get distance profiles for all trips in parallel\n",
    "def get_distance_profiles_parallel(windows_df, df_bc, time_series_columns, n_jobs=-1):\n",
    "    results = []  # List to accumulate results\n",
    "\n",
    "    # Loop over each query\n",
    "    for query_num in windows_df['seg_num_id'].unique():\n",
    "        query_df = windows_df[windows_df['seg_num_id'] == query_num].copy()\n",
    "        query_trip_num = query_df['trip_num'].values[0]\n",
    "\n",
    "        # Use Parallel to process each trip in parallel\n",
    "        trip_results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(compute_mass_for_trip)(query_df, df_bc[df_bc['trip_num'] == trip_num].copy(), query_num, trip_num, time_series_columns)\n",
    "            for trip_num in df_bc['trip_num'].unique()\n",
    "            if trip_num != query_trip_num  # Skip the query's own trip\n",
    "        )\n",
    "\n",
    "        # Filter out None results (trips that were skipped)\n",
    "        trip_results = [result for result in trip_results if result is not None]\n",
    "\n",
    "        # Append the valid results to the main results list\n",
    "        results.extend(trip_results)\n",
    "\n",
    "    # Convert accumulated results into a DataFrame\n",
    "    distance_profiles_dict = results\n",
    "\n",
    "    return distance_profiles_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Near Miss Algorithm (nma)\n",
    "- Input: windows_df, df_bc, time_series_columns\n",
    "- Output: distance_profiles_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The initial columns to compare in the time series data\n",
    "time_series_columns = ['veh_long_vel_mps', 'veh_accel_mps2', 'veh_ltrl_vel_mps', 'veh_yaw_rate_radps', 'veh_jerk_mps3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 5303.12 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "distance_profiles = get_distance_profiles_parallel(windows_df, df_bc, time_series_columns)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the output dictionary\n",
    "- Dictionary Fields: trip_num (int), query_num (int), distance_profile (np array), min_distance (float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the distance profiles dictionary to a file - Rename to appropriate name\n",
    "with open('data/nma_distance_profiles_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(distance_profiles, f)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m114"
  },
  "kernelspec": {
   "display_name": "env_bc_eda",
   "language": "python",
   "name": "env_bc_eda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
